---
title: 使用AI测试代码
vid: f0ff08f733fd71f0bfe05017f1e80102
---

**文档地址**： [https://course.oneday.build/cn/docs/workflow](https://course.oneday.build/cn/docs/workflow)
- **回顾上一节**：成功将SupaMCP第一个版本提交至GitHub，利用GitHub MCP实现快速提交。
- **本节目标**：对SupaMCP程序进行全面测试，确保功能可靠性。
- **测试重要性**：测试是开发中常被忽略的环节，需覆盖成功、失败和边缘场景。

## 2. 提示工程（Prompt Engineering）
- **模块化Prompt原则**：
  - 好的提示：一次只要求AI完成一件事（如“更新列表记录函数，添加过滤参数”）。
  - 坏的提示：一次要求多件事，易导致AI输出不可控。
- **应用示例**：
  - 上一节GitHub提交分三步（创建仓库、配置.gitignore、上传代码），逐一明确指令。
  - 确保AI任务清晰，提升输出质量。

## 3. 测试环节的核心原则
- **测试必要性**：
  - 个人开发常忽略系统测试，仅靠手动验证不足以确保稳定性。
  - 需编写测试用例，覆盖三种场景：成功、失败、边缘。
- **全局规则支持**：
  - 全局规则已定义测试要求（成功、失败、边缘场景，测试文件置于`test`文件夹）。
  - AI基于规则自动生成测试用例，无需开发者深入了解测试工具（如Mock）。

## 4. 测试实施过程
- **测试环境**：
  - 所有测试在`test`文件夹下进行，隔离原始文件，防止意外修改。
  - 测试文件针对`server.py`，覆盖核心功能（读、写、更新、删除）。
- **测试执行**：
  - 指令：要求AI在`test/SupaMCP`下创建`server.py`的测试用例。
  - 初始测试：生成8个测试用例（4个功能×2个场景），全部通过。
  - 问题发现：缺少失败场景用例，未达预期12个测试（4功能×3场景）。
  - 优化：补充失败场景测试用例，重新运行，12个测试全部通过。
- **测试优势**：
  - AI生成测试用例高效、可靠，降低测试开发门槛。
  - 开发者仅需提供场景描述，无需编写复杂测试代码。

## 5. 测试结果
- **成果**：SupaMCP核心功能通过全面测试，验证了程序稳定性。
- **意义**：测试过程简单高效，适合个人开发者，取代传统测试团队工作。

## 6. 下一步计划
- **部署服务**：进入最后一个环节，准备将SupaMCP服务部署上线。
- **功能扩展**：进一步优化测试覆盖，完善复杂功能。